name: Parsl

on:
  pull_request:
    types:
      - opened
      - synchronize

jobs:
  main-test-suite:
    strategy:
      matrix:
        python-version: ["3.10"]
    runs-on: ubuntu-20.04
    timeout-minutes: 30

    steps:
    - uses: actions/checkout@master

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v1
      with:
        python-version: ${{ matrix.python-version }}

    - name: Non-requirements based install
      run: |
        sudo apt-get update -q
        python --version

        # this is to make the workqueue binary installer happy
        sudo apt-get install -y libpython3.5

    - name: make deps clean_coverage
      run: |
        make deps
        make clean_coverage

    - name: make test
      run: |
        make test

    - name: Documentation checks
      run: |
        pip install .[docs]
        sudo apt-get install -y pandoc
        cd docs

        test ! -e stubs

        # check we can build the docs without warnings
        make SPHINXOPTS=-W html

        cd ..

        # assert that none of the runs in this test have put an ERROR message into a
        # database manager log file or monitoring router log file. It would be better if
        # the tests themselves failed immediately when there was a monitoring error, but
        # in the absence of that, this is a dirty way to check.
        bash -c '! grep ERROR runinfo*/*/database_manager.log'
        bash -c '! grep ERROR runinfo*/*/monitoring_router.log'

    - name: Checking parsl-visualize
      run: |
        sudo apt-get install -y graphviz
        pip install .[monitoring]
        parsl/tests/test-viz.sh

    - name: make coverage
      run: |
        make coverage

    - name: Archive runinfo logs
      if: ${{ always() }}
      uses: actions/upload-artifact@v2
      with:
        name: runinfo-${{ matrix.python-version }}
        path: runinfo/
