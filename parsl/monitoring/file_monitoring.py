"""
This module defines the file monitoring infrastructure.
"""
import datetime
import logging
import glob
from functools import wraps
import typeguard
import socket
import os
import time
from multiprocessing import pool, Event, Pool
import dill
import re
from typing import List, Callable, Any, Dict, Union, Optional, Tuple
from parsl.multiprocessing import ForkProcess

logger = logging.getLogger(__name__)


def proc_callback(res: Any) -> None:
    """Callback function for the results of running a function in the Pool.

       Writes result of the monitoring run to the log

       Parameters
       ----------
       res: Any
           Can really be anything that can be cast directly to a string.
    """
    # if there is no message
    if not res:
        return
    # type check the input and cast as appropriate
    if not isinstance(res, str):
        if isinstance(res, (bytes, bytearray)):
            try:
                res = res.decode()
            except Exception as ex:
                logger.error(f"Could not decode bytes like object: {str(ex)}")
                return
        else:
            try:
                res = str(res)
            except Exception as ex:
                logger.error(f"Could not turn data into string: {str(ex)}")
                return
    logging.info(res)


def run_dill_encoded(payload: str) -> Any:
    """Take the dill encoded payload, decode, and run it.

    Parameters
    ----------
    payload: str
        String generated by calling dill.dumps

    Returns
    -------
    Any
        The result of running the decoded function
    """
    fun, args = dill.loads(payload)
    return fun(*args)


def apply_async(monitor_pool: Any,  # cannot be Pool because of multiprocessing type weirdness.
                fun: Callable, args: Any) -> pool.AsyncResult:
    """Encode the given function and run it asynchronously.

    This is used to get around the pickl issue of not being able to encode functions that
    are not visible at the global scope.

    Parameters
    ----------
    monitor_pool: mp.Pool
        Pool object use to run the function
    fun: Callable
        The function to encode and run
    args: Any
        The function arguments

    Returns
    -------
    mp.Pool.AsyncResult
    """
    payload = dill.dumps((fun, args))
    return monitor_pool.apply_async(run_dill_encoded, (payload,), callback=proc_callback)


@typeguard.typechecked
def monitor(task_id: int,
            stop_event: Any,  # cannot be Event because of multiprocessing type weirdness.
            done_event: Any,  # cannot be Event because of multiprocessing type weirdness.
            patterns: List[Any],
            callbacks: List[Callable],
            sleep_dur: float,
            work_dir: Optional[str] = None,
            max_proc: int = 2) -> None:
    """Function to monitor the file system for specific types of files and call a function when they are found.

    This function runs in a periodic loop unitl it is told to stop. The time between loops is goverened by `sleep_dur`
    seconds. Multiprocessing.Event objects are used to signal when this function should terminate. The general
    workflow is as follows::
                                        ------>callack (async)
                                        |
                     -----(found)-------+-------
                     |                         |
    Start----->scan for files---(none found)---+-->sleep --
                    ^                                     |
                    |                                     |
                    ---------------------------------------

    Any files that match any given pattern are tracked and only submitted to the callbacks once.

    Parameters
    ----------
    task_id: int
        The Parsl task id to be monitored.
    stop_event: multiprocessing.Event
        Signal for when to stop running the loop
    done_event: nultiprocessing.Event
        Signal used to indicate when this is actually completed, alowing for currently running callbacks to
        complete nicely.
    patterns: list
        List of tuples containing a regex or glob type statement and a bool indicating whther it is regex (True) or not,
        for finding the files.
    callbacks: list
        List of functions to call when files are found. This list must have either a single entry for all
        `patterns` or have the same length as `patterns` (one callback for each pattern).
    sleep_dur: float
        The length of time to sleep between loops in seconds.
    work_dir: str
        The working directory for this process to run in. Default is ``None``, meaning the working directory is
        inherited from the calling process.
    max_proc: int, optional
        The maximum size of the multiprocessing Pool for the file processing. Default is 2, but the
        value is adjusted to be ``min(max_proc, len(patterns))`` so as to not make the pool larger than
        needed.
    """
    try:
        if work_dir is not None:
            os.chdir(work_dir)
        monitor_pool = Pool(min(max_proc, len(patterns)))

        logger.info(f"Monitor host {socket.gethostname()} started for task {task_id}")
        found = []
        keep_running = True
        running_procs = []  # keep track of all callback runs
        while keep_running:
            # see if the function has been told to stop
            keep_running = not stop_event.is_set()
            if not keep_running:
                logger.info(f"  {stop_event.is_set()} received {str(datetime.datetime.now())}")
                sleep_dur = 0
            # loop over all the patterns looking for new matches
            for i in range(len(patterns)):
                logger.debug(f" {i} {patterns[i]}")
                xfer = []
                current_time = time.time()
                # look for any matching files
                if patterns[i][1]:
                    temp = [f for f in os.listdir(os.getcwd()) if patterns[i][0].search(f)]
                else:
                    temp = glob.glob(patterns[i][0])
                # weed out those that have been found before and any that are too new
                for t in temp:
                    if t in found:
                        continue
                    mtime = os.path.getmtime(t)
                    # make sure the file is done.
                    if mtime + sleep_dur < current_time:
                        xfer.append(t)
                if not xfer:
                    logger.debug(f"No files found for processing task {task_id}, pattern {i}.")
                    continue
                logger.debug(f"Found {len(xfer)} files for processing")
                # matches were found, sending them to callback
                running_procs.append(apply_async(monitor_pool, callbacks[i], (xfer,)))
                found += xfer
            if not keep_running:
                # the loop is terminating, wait for callbacks to finish
                monitor_pool.close()
                monitor_pool.join()
                monitor_pool.terminate()
            else:
                time.sleep(sleep_dur)
        logger.debug(f"HALT called for task {task_id}")
        # signal the function is complete
    except Exception as ex:
        logger.error(f"File monitor failed: {str(ex)}")
    finally:
        done_event.set()


@typeguard.typechecked
class FileMonitor:
    """The FileMonitor calss is an interface for defining any intermediate files that need to be processed mid-run.
    See :ref:`file-monitor-label` for a more detailed description of this system.

    Parameters
    ----------
    callback: Callable or List[Callable]
        A function or list of functions to call when files are found that match the given patterns. If a
        single function is given then it will be called for all pattern matchs; if a list of functions are
        given then there must be one for each pattern given, in the order they match the patterns(e.g. pattern 1
        matches will be sent to callback 1). Callback functions should either return None or something
        that can be cast to a string.
    pattern: str, List[str], optional
        A single regex style pattern or a list of regex style patterns for finding files. At least one ``pattern`` or
        ``filetype`` must be given.
    filetype: str, List[str], optional
        A single filetype or a list of filetypes to watch for. Can be with or without an asterisk and period
        (e.g. ``pdf``, ``.pdf``, and ``*.pdf`` all are valid and mean the same thing). At least one ``pattern``
        or ``filetype`` must be given.
    path: str, optional
        The base path where the files are expected to be, default is current working directory (``None``).
    working_dir: str, optional
        The working directory for the file monitoring, default (``None``) is the current working directory
        inherited when the monitor process is started.
    sleep_dur: float
        The time to wait between scans of the file system to look for matching files. Default is 60 seconds.
    max_proc: int, optional
        The maximum size of the multiprocessing Pool for the file processing. Default is 4, but the
        value is adjusted to be ``min(max_proc, len(patterns))`` so as to not make the pool larger than
        needed.
    """
    def __init__(self,
                 callback: Union[Callable, List[Callable]],
                 pattern: Optional[Union[str, List[str]]] = None,
                 filetype: Optional[Union[str, List[str]]] = None,
                 path: Optional[str] = None,
                 working_dir: Optional[str] = None,
                 sleep_dur: float = 60.,
                 max_proc: int = 2):
        logger.info(f"File_monitor initialized: {path}, {working_dir}, {sleep_dur}")
        # generate the master pattern list
        self.patterns: List[Tuple[Any, bool]] = []
        if pattern is not None:
            if isinstance(pattern, list):
                for p in pattern:
                    self.patterns.append((re.compile(p), True))
            else:
                self.patterns = [(re.compile(pattern), True)]
        if filetype is not None:
            temppat = []
            if isinstance(filetype, list):
                temppat = filetype
            else:
                temppat.append(filetype)
            if path is not None:
                for i, pat in enumerate(temppat):
                    if '*' not in pat:
                        if not pat.startswith('.'):
                            pat = '.' + pat
                        pat = '*' + pat
                    temppat[i] = os.path.join(path, pat)
            else:
                for i, pat in enumerate(temppat):
                    if '*' not in pat:
                        if not pat.startswith('.'):
                            pat = '.' + pat
                        pat = '*' + pat
                    temppat[i] = pat
            for ft in temppat:
                self.patterns.append((ft, False))
        if not self.patterns:
            raise Exception("Either pattern or filetype must be given")
        if isinstance(callback, list):
            if len(self.patterns) != len(callback):
                raise Exception("Pattern list is not the same size as function list")
            self.callbacks = callback
        else:
            self.callbacks = [callback] * len(self.patterns)
        self.sleep_dur = sleep_dur
        self.cwd = working_dir
        self.max_proc = max_proc

    def file_monitor(self,
                     f: Any,
                     task_id: int) -> Callable:
        """Function wrapper for launching the monitoring

        Parameters
        ----------
        f: Callable
            The function to wrap
        task_id: int
            The Parsl task id to be monitored.

        Returns
        -------
        Callable
            The given function wrapped by the monitoring code.

        """
        @wraps(f)
        def wrapped(*args: List[Any], **kwargs: Dict[str, Any]) -> Any:
            ev = Event()
            done = Event()
            pp = ForkProcess(target=monitor,
                             args=(task_id,
                                   ev,
                                   done,
                                   self.patterns,
                                   self.callbacks,
                                   self.sleep_dur,
                                   self.cwd,
                                   self.max_proc))
            pp.start()
            try:
                return f(*args, **kwargs)
            finally:
                ev.set()
                pp.join(self.sleep_dur)
                if pp.exitcode is None:
                    pp.terminate()
                    pp.join()
        return wrapped
